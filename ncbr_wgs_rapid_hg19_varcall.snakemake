#################################
#
# snakefile for converting CIDR Sequencing data deliveries to non-PII ready for GRIS upload, running QC, and joint genotyping
#
# Susan Huse, susan.huse@nih.gov
# Frederick National Lab
# April 10, 2019
#
# Justin Lack
# Frederick National Lab
# December 11, 2019
#
#################################

## 
## Load python modules
##
import os
from os import listdir
from os.path import join
import pandas as pd
import re
import sys
from glob import glob
import datetime

##
## Set initial global variables
##
dir_renamed = os.getcwd()
dir_rawdata = join(dir_renamed, "rawdata")
dir_hla_master = "/sysapps/cluster/software/HLA-LA/1.0/HLA-LA-master"
batch_number = re.sub("^.*batch","",dir_renamed)
batch_name = "batch" + batch_number
#if int(batch_number) < 10:
#    batch_name0 = "BATCH0" + batch_number
#else:
#    batch_name0 = "BATCH" + batch_number

#dir_rawvcf = join(dir_rawdata, "MultiSampleVCF", "withGenotypeRefinement")
#VCF = [f for f in os.listdir(dir_rawvcf) if re.match(r'.*.vcf.gz$', f)][0]
#VCF = join(dir_rawvcf, VCF)
#fnames = ["cumulative_coverage_counts", "cumulative_coverage_proportions", "gene_summary", "interval_statistics", "interval_summary", "statistics", "summary"]

## Check if these are bams or crams
#if os.path.isdir(os.path.join(dir_rawdata, "CRAM")):
#    seqdir = "CRAM"
#    seqfile = ".cram"
#elif os.path.isdir(os.path.join(dir_rawdata, "BAM")):
#    seqdir = "BAM"
seqfile = ".bam"
#else:
#    print("Unable to locate input rawdata BAM or CRAM folder.  Quitting.")
#    sys.exit()


## Set variables for rerunning all of the old pedigrees
last_batch = str(int(batch_number) - 1)
#dir_peds = "/hpcdata/dir/CIDR_DATA_RENAMED/pedigrees_updated"
#dir_peds = "/data/NCBR/projects/csi_test_batch/pedigrees_updated"
todays_date = re.sub('-','',str(datetime.datetime.today()).split()[0])

##
## Read in the masterkey file 
##
#print(listdir(os.getcwd()))
df = pd.read_csv("masterkey.txt", header=0, sep='\t')
#df = df.loc[(df['Batch_Received'].isin([batch_name0, ""])) | (df['Batch_Received'].isnull())]
dict_CIDR = dict(zip(df['IDs'].tolist(), df['Names'].tolist()))
#dict_CIDR = df['Names'].tolist()
print(dict_CIDR)
#exit

configfile:"NCBR_wgs_pipeline/ncbr_wgs_references.json"
chroms = ["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","X","Y","MT"]
chunks = ['1:1-30000001','1:30000001-60000001','1:60000001-90000001','1:90000001-120000001','1:120000001-150000001','1:150000001-180000001','1:180000001-210000001','1:210000001-240000001','1:240000001-249250621','2:1-30000001','2:30000001-60000001','2:60000001-90000001','2:90000001-120000001','2:120000001-150000001','2:150000001-180000001','2:180000001-210000001','2:210000001-240000001','2:240000001-243199373','3:1-30000001','3:30000001-60000001','3:60000001-90000001','3:90000001-120000001','3:120000001-150000001','3:150000001-180000001','3:180000001-198022430','4:1-30000001','4:30000001-60000001','4:60000001-90000001','4:90000001-120000001','4:120000001-150000001','4:150000001-180000001','4:180000001-191154276','5:1-30000001','5:30000001-60000001','5:60000001-90000001','5:90000001-120000001','5:120000001-150000001','5:150000001-180000001','5:180000001-180915260','6:1-30000001','6:30000001-60000001','6:60000001-90000001','6:90000001-120000001','6:120000001-150000001','6:150000001-171115067','7:1-30000001','7:30000001-60000001','7:60000001-90000001','7:90000001-120000001','7:120000001-150000001','7:150000001-159138663','8:1-30000001','8:30000001-60000001','8:60000001-90000001','8:90000001-120000001','8:120000001-146364022','9:1-30000001','9:30000001-60000001','9:60000001-90000001','9:90000001-120000001','9:120000001-141213431','10:1-30000001','10:30000001-60000001','10:60000001-90000001','10:90000001-120000001','10:120000001-135534747','11:1-30000001','11:30000001-60000001','11:60000001-90000001','11:90000001-120000001','11:120000001-135006516','12:1-30000001','12:30000001-60000001','12:60000001-90000001','12:90000001-120000001','12:120000001-133851895','13:1-30000001','13:30000001-60000001','13:60000001-90000001','13:90000001-115169878','14:1-30000001','14:30000001-60000001','14:60000001-90000001','14:90000001-107349540','15:1-30000001','15:30000001-60000001','15:60000001-90000001','15:90000001-102531392','16:1-30000001','16:30000001-60000001','16:60000001-90000001','16:90000001-90354753','17:1-30000001','17:30000001-60000001','17:60000001-81195210','18:1-30000001','18:30000001-60000001','18:60000001-78077248','19:1-30000001','19:30000001-59128983','20:1-30000001','20:30000001-60000001','20:60000001-63025520','21:1-30000001','21:30000001-48129895','22:1-30000001','22:30000001-51304566','X:1-30000001','X:30000001-60000001','X:60000001-90000001','X:90000001-120000001','X:120000001-150000001','X:150000001-155270560','Y:1-30000001','Y:30000001-59373566','MT:1-16569']
lanes = ["L001","L002","L003","L004"]

##
## Set rule all
##
rule all:
    input:
        vcf = "VCF/COVID_WGS_" + batch_name + ".vcf.gz",
        hla = expand(join(dir_renamed, "HLA", "{newID}", "sample", "hla", "R1_bestguess_G.txt"), newID=list(dict_CIDR.keys())),
        table = expand(join(dir_renamed, "HLA/{newID}_hla.xlsx"), newID=list(dict_CIDR.keys())),
        final="VCF/snps_and_indels_recal_refinement_variants.vcf.gz",
#        gvcfs=expand("gVCFs/{newID}.{chunks}.g.vcf.gz", newID=list(dict_CIDR.keys()), chunks=chunks),

rule haplotypecaller:
    input: 
        bam="BAM/{newID}.recal.bam",
    output:
        gzvcf = temp("gVCFs/{newID}.{chunks}.g.vcf.gz"),
        index = temp("gVCFs/{newID}.{chunks}.g.vcf.gz.tbi"),
    params: 
        sample = "{newID}",rname = "hapcaller",genome = config['references']['GENOME'],regions = config['references']['REGIONS'],snpsites=config['references']['DBSNP'], chunk="{chunks}"
    shell:
        """
        mkdir -p gVCFs
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' HaplotypeCaller --reference {params.genome} --input {input.bam} --use-jdk-inflater --use-jdk-deflater --emit-ref-confidence GVCF --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --dbsnp {params.snpsites} --output {output.gzvcf} --intervals {params.chunk} --max-alternate-alleles 3
        """

rule listgvcfs:
    input: 
        gzvcf = expand("gVCFs/{newID}.{{chunks}}.g.vcf.gz",newID=list(dict_CIDR.keys())),
        index = expand("gVCFs/{newID}.{{chunks}}.g.vcf.gz.tbi",newID=list(dict_CIDR.keys())),
    output:
        list = "gVCFs/gVCFs.{chunks}.list"
    params: 
        rname = "listgvcfs",genome = config['references']['GENOME'],batch=batch_name, chunk="{chunks}"
    shell:
        """
        ls gVCFs/*.{params.chunk}.g.vcf.gz > {output.list}
        """

rule mergegvcfs:
    input: list = "gVCFs/gVCFs.{chunks}.list",
           gzvcf = expand("gVCFs/{newID}.{{chunks}}.g.vcf.gz",newID=list(dict_CIDR.keys())),
           index = expand("gVCFs/{newID}.{{chunks}}.g.vcf.gz.tbi",newID=list(dict_CIDR.keys())),
           prev = "/data/GRIS_NCBR/COVID_WGS/hg19_gvcfs/cumulative/through_batch" + last_batch + "_{chunks}.g.vcf.gz"
    output:
        gzvcf = "/data/GRIS_NCBR/COVID_WGS/hg19_gvcfs/cumulative/through_batch" + batch_number + "_{chunks}.g.vcf.gz",
        index = "/data/GRIS_NCBR/COVID_WGS/hg19_gvcfs/cumulative/through_batch" + batch_number + "_{chunks}.g.vcf.gz.tbi",
    params: 
        rname = "mergegvcfs",genome = config['references']['GENOME'], chunk="{chunks}", batch=batch_name
    shell:
        """
        module load GATK/4.1.4.1
        mkdir -p gVCFs/merged
        gatk --java-options '-Xmx24g' CombineGVCFs --reference {params.genome} --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --variant {input.list} --variant {input.prev} --output {output.gzvcf} --intervals {params.chunk} --use-jdk-inflater --use-jdk-deflater
        """

rule genotype:
    input: 
        gzvcf = "/data/GRIS_NCBR/COVID_WGS/hg19_gvcfs/cumulative/through_batch" + batch_number + "_{chunks}.g.vcf.gz",
        index = "/data/GRIS_NCBR/COVID_WGS/hg19_gvcfs/cumulative/through_batch" + batch_number + "_{chunks}.g.vcf.gz.tbi",
    output:
        vcf = "VCF/by_chunk/raw_variants_{chunks}.vcf.gz",
    params:
        rname = "genotype",genome = config['references']['GENOME'],snpsites=config['references']['DBSNP'],chr="{chunks}"
    shell:
        """
        mkdir -p VCF/by_chunk
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx96g' GenotypeGVCFs --reference {params.genome} --use-jdk-inflater --use-jdk-deflater --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --dbsnp {params.snpsites} --output {output.vcf} --variant {input.gzvcf} --intervals {params.chr}
        """

rule merge_chunk:
    input:
        expand("VCF/by_chunk/raw_variants_{chunks}.vcf.gz", chunks=chunks),
    output:
        vcf = "VCF/raw_variants.vcf.gz",
        list = "VCF/by_chunk/raw_variants_bychunk.list",
    params:
        rname = "merge_chunk", genome = config['references']['GENOME']
    shell:
        """
        ls -d $PWD/VCF/by_chunk/raw_variants_*.vcf.gz > VCF/by_chunk/raw_variants_bychunk.list
        module load GATK/4.1.8.0
        gatk MergeVcfs --OUTPUT {output.vcf} --INPUT {output.list}
        """

rule vqsr_snp:
    input: 
        vcf = "VCF/raw_variants.vcf.gz",
    output:
        recal = "VCF/SNP.output.AS.recal",
        tranches = "VCF/SNP.output.AS.tranches",
        rscript = "VCF/SNP.output.plots.AS.R",
    params: 
        rname = "vqsr_snp",genome=config['references']['GENOME'],dbsnp=config['references']['DBSNP'],onekg=config['references']['1000GSNP'],hapmap=config['references']['HAPMAP'],omni=config['references']['OMNI']
    shell:
        """
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' VariantRecalibrator --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.8 -tranche 99.6 -tranche 99.5 -tranche 99.4 -tranche 99.3 -tranche 99.0 -tranche 98.0 -tranche 97.0 -tranche 90.0 --max-gaussians 6 --reference {params.genome} --use-jdk-inflater --use-jdk-deflater -AS -V {input.vcf} --resource:hapmap,known=false,training=true,truth=true,prior=15.0 {params.hapmap} --resource:omni,known=false,training=true,truth=false,prior=12.0 {params.omni} --resource:1000G,known=false,training=true,truth=false,prior=10.0 {params.onekg} --resource:dbsnp,known=true,training=false,truth=false,prior=2.0 {params.dbsnp} -an QD -an DP -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -mode SNP -O VCF/SNP.output.AS.recal --tranches-file VCF/SNP.output.AS.tranches --rscript-file VCF/SNP.output.plots.AS.R
        """

rule vqsr_indel:
    input: 
        vcf = "VCF/raw_variants.vcf.gz",
    output:
        recal = "VCF/INDEL.output.AS.recal",
        tranches = "VCF/INDEL.output.AS.tranches",
        rscript = "VCF/INDEL.output.plots.AS.R",
    params: 
        rname = "vqsr_indel",genome = config['references']['GENOME'],mills=config['references']['MILLS'],dbsnp=config['references']['DBSNP']
    shell:
        """
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' VariantRecalibrator --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 --reference {params.genome} --use-jdk-inflater --use-jdk-deflater -AS -V {input.vcf} --resource:mills,known=false,training=true,truth=true,prior=12.0 {params.mills} --resource:dbsnp,known=true,training=false,truth=false,prior=2.0 {params.dbsnp} -an QD -an DP -an FS -an SOR -an ReadPosRankSum -an MQRankSum -mode INDEL -O VCF/INDEL.output.AS.recal --tranches-file VCF/INDEL.output.AS.tranches --rscript-file VCF/INDEL.output.plots.AS.R --max-gaussians 4
        """

rule apply_snp:
    input: 
        vcf = "VCF/raw_variants.vcf.gz",
        recal = "VCF/SNP.output.AS.recal",
        tranches = "VCF/SNP.output.AS.tranches",
    output:
        vcf = "VCF/snps_recal_variants.vcf.gz",
    params: 
        rname = "apply_snps",genome = config['references']['GENOME']
    shell:
        """
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' ApplyVQSR --create-output-variant-index true --reference {params.genome} -AS --use-jdk-inflater --use-jdk-deflater -V {input.vcf} -mode SNP --recal-file VCF/SNP.output.AS.recal --tranches-file VCF/SNP.output.AS.tranches --truth-sensitivity-filter-level 99.7 -O {output.vcf}
        """

rule apply_indel:
    input: 
        vcf = "VCF/snps_recal_variants.vcf.gz",
        recal = "VCF/INDEL.output.AS.recal",
        tranches = "VCF/INDEL.output.AS.tranches",
    output:
        vcf = "VCF/snps_and_indels_recal_variants.vcf.gz",
    params: 
        rname = "apply_indels",genome = config['references']['GENOME']
    shell:
        """
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' ApplyVQSR --reference {params.genome} -AS --use-jdk-inflater --use-jdk-deflater -V {input.vcf} -mode INDEL --recal-file VCF/INDEL.output.AS.recal --tranches-file VCF/INDEL.output.AS.tranches --truth-sensitivity-filter-level 99.7 -O {output.vcf}
        """

rule gtype_refinement:
    input: 
        vcf = "VCF/snps_and_indels_recal_variants.vcf.gz",
    output:
        vcf = "VCF/snps_and_indels_recal_refinement_variants.vcf.gz",
        gtfix_vcf = "VCF/snps_and_indels_recal_refinement_variants.GTfix.vcf.gz",
    params: 
        rname = "gtype_refinement",genome = config['references']['GENOME'],onekg = config['references']['1000G'],exac=config['references']['EXAC']
    shell:
        """
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' CalculateGenotypePosteriors --reference {params.genome} --use-jdk-inflater --use-jdk-deflater -V {input.vcf} -supporting {params.onekg} -supporting {params.exac} -O {output.vcf}
        module load bcftools
        bcftools +setGT {input.vcf} -O z -o {output.gtfix_vcf} -- -t a -n u
        tabix -p vcf {output.gtfix_vcf}
        """

###
### Subset VCF
###
###
rule vcf:
    input: 
        vcf = "VCF/snps_and_indels_recal_refinement_variants.vcf.gz",
    output:
        vcf = "VCF/COVID_WGS_" + batch_name + ".vcf.gz",
        gtfix_vcf = "VCF/COVID_WGS_" + batch_name + ".GTfix.vcf.gz",
    params:
        rname = "VCF_rename",genome = config['references']['GENOME']
    shell:
        """
        tail -n +2 masterkey.txt | cut -f2 > samples.args
        module load GATK/4.1.4.1
        gatk --java-options '-Xmx24g' SelectVariants --reference {params.genome} -V {input.vcf} -O {output.vcf} -sn samples.args --keep-original-ac --exclude-non-variants
        module load bcftools
        bcftools +setGT {output.vcf} -O z -o {output.gtfix_vcf} -- -t a -n u
        tabix -p vcf {output.gtfix_vcf}
        """

##
## Calculate HLA for all BAM files
##
rule hla:
    input: 
        bam="BAM/{newID}.recal.bam",
    output: 
        hla = join(dir_renamed, "HLA", "{newID}", "sample", "hla", "R1_bestguess_G.txt"),
    params: 
        rname = "hla",
        sample = "{newID}",
        hladir = join(dir_renamed, "HLA")
    shell: 
        """
        module load HLA-PRG-LA/1.0.1
        mkdir -p HLA
        HLA-LA.pl --BAM {input.bam} --graph PRG_MHC_GRCh38_withIMGT  --sampleID sample --maxThreads 7 --workingDir {params.hladir}/{params.sample}"""
        
##
## Concatenate Batch HLA files into one table
##
rule hla_concat:
    input: hla = join(dir_renamed, "HLA", "{newID}", "sample", "hla", "R1_bestguess_G.txt"),
    output: table = join(dir_renamed, "HLA/{newID}_hla.xlsx"),
    params:
        rname = "hla",
        hladir = join(dir_renamed, "HLA"),
        sample = "{newID}",
    shell:
        """
        python /data/GRIS_NCBR/resources/software/hla_xlsx.py -i {input.hla} -o {output.table} -s {params.sample}
        """

rule smoove:
    input: 
        bam="BAM/{newID}.recal.bam",
    output:
        vcf = "smoove_out/{newID}/{newID}-smoove.genotyped.vcf.gz",
    params: 
        sample = "{newID}",rname = "smoove", genome = config['references']['GENOME'], exclusions = config['references']['SMOOVEEXCLUSIONS']
    shell:
        """
        mkdir -p smoove_out
        mkdir -p smoove_out/{params.sample}
        module load smoove/0.2.5
        smoove call --outdir smoove_out/{params.sample} --exclude {params.exclusions} --name {params.sample} --fasta {params.genome} -p 4 --genotype {input.bam}
        """

rule smoove_merge:
    input: 
        expand("smoove_out/{newID}/{newID}-smoove.genotyped.vcf.gz",newID=list(dict_CIDR.keys())),
    output:
        vcf = "smoove_out/merged.sites.vcf.gz",
    params: 
        rname = "smoove_merge",genome = config['references']['GENOME']
    shell:
        """
        module load smoove/0.2.5
        smoove merge --outdir smoove_out --name merged --fasta {params.genome} {input}
        """

rule smoove_gtype:
    input: 
        merge = "smoove_out/merged.sites.vcf.gz",
        vcf = "smoove_out/{newID}/{newID}-smoove.genotyped.vcf.gz",
        bam="BAM/{newID}.recal.bam",
    output:
        vcf = "smoove_out/{newID}/{newID}-joint-smoove.genotyped.vcf.gz",
    params: 
        sample = "{newID}",rname = "smoove_gtype",genome = config['references']['GENOME']
    shell:
        """
        module load smoove/0.2.5
        smoove genotype -d -x -p 4 --name {params.sample}-joint --outdir smoove_out/{params.sample} --fasta {params.genome} --vcf {input.merge} {input.bam}
        """

rule smoove_paste:
    input: 
        expand("smoove_out/{newID}/{newID}-joint-smoove.genotyped.vcf.gz",newID=list(dict_CIDR.keys())),
    output:
        vcf = "smoove_out/batch.smoove.square.vcf.gz",
    params: 
        rname = "smoove_paste"
    shell:
        """
        module load smoove/0.2.5
        smoove paste --name batch --outdir smoove_out {input}
        """
